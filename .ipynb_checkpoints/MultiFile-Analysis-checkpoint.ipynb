{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f2b34f",
   "metadata": {},
   "source": [
    "## Multiple File Exploration and Analysis\n",
    "\n",
    "This workbook will load the data created in \"MultiFile-Prep\" to build a topic model using Gensim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb2f65a",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "We exported the prepared data frame as a pickle file, so we'll read it back into pandas here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_df = pd.read_pickle('processed_data/ucsf_medical.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3aa6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ac3be",
   "metadata": {},
   "source": [
    "### Format Create Word Vectors for Gensim\n",
    "\n",
    "Gensim requires a specific formatting for term frequency vectors. We'll go through the existing dataframe line-by-line to create and populate these lists.\n",
    "\n",
    "For topic modeling or other natural language processing projects, you often need to decide on how broadly or narrowly you want to define a document. For example, you could define a document to be a sentence, paragraph, page, or multi-page publication. \n",
    "\n",
    "For this exercise, we'll consider each *page* in the corpus to be a document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_text_lists = []\n",
    "text_len = []\n",
    "\n",
    "for i,r in vol_df.iterrows():\n",
    "    words = r.page_tokens\n",
    "    bow_text_lists.append(words)\n",
    "    bow_text = []\n",
    "    for word in words:\n",
    "        bow_text.append(word)\n",
    "    text_len.append(len(bow_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b1b8e",
   "metadata": {},
   "source": [
    "### Word Vectors\n",
    "\n",
    "We have 208 documents (defined as a page) in our collection, ranging from 72 to 478 words per document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff4df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bow_text_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f21b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max:\", max(text_len), \"min:\", min(text_len), \"mean:\", np.mean(text_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060aecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91b22fd",
   "metadata": {},
   "source": [
    "### Create Gensim dictionary and corpus\n",
    "\n",
    "A dictionary provides an id-to-token lookup for every word in the corpus (our \"bag-of-words\")\n",
    "\n",
    "Our corpus provides a term frequency vector for each document in our collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f14a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(bow_text_lists)\n",
    "corpus = [dictionary.doc2bow(text) for text in bow_text_lists]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16788894",
   "metadata": {},
   "source": [
    "Take a look at our dictionary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7124297",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "\n",
    "for k,v in dictionary.items():\n",
    "    if n <= 15:\n",
    "        print(f\"{k} : {v}\")\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6bad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vol_df.iloc[18]['page_tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01311d45",
   "metadata": {},
   "source": [
    "... and the term frequency for one of the documents (pages) in our corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e133e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a small subset to display\n",
    "corpus[10][20:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb7211",
   "metadata": {},
   "source": [
    "The term frequency is stored in sparse matrix format, as most words in the entire corpus won't show up in each individual document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the terms included\n",
    "for c in corpus[10][20:30]:\n",
    "    print(dictionary[c[0]], c[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a46602",
   "metadata": {},
   "source": [
    "### Decide on a number of clusters and create a topic model\n",
    "\n",
    "Because we split our collection into two groups, \"nursing\" and \"dentistry\", let's choose 2 topics to start. Keep in mind, our topic model may not neatly divide these pages into two different clusters, because the topics discussed may overlap substantially!\n",
    "\n",
    "Choosing the number of topics is partly art, though there are strategies you can use. For now, try experimenting with different numbers of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d06757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this could take a while to run\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "number_of_topics = 2\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = number_of_topics, id2word=dictionary, passes=50)\n",
    "#ldamodel.save('model10.gensim')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e165ad75",
   "metadata": {},
   "source": [
    "### Topics and word frequency\n",
    "\n",
    "Let's look at the words most associated with each of the (two) topics Gensim identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b6b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ldamodel.show_topics(num_words=20, formatted=False)\n",
    "for topic in topics:\n",
    "    print(\"topic:\", topic[0])\n",
    "    for term in topic[1]:\n",
    "        print(term)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86818576",
   "metadata": {},
   "source": [
    "### Term frequency\n",
    "\n",
    "Look up the term frequency for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd77aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.get_term_topics('nursing', minimum_probability=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd700c",
   "metadata": {},
   "source": [
    "### Topic visualization\n",
    "\n",
    "pyLDAvis provides really excellent visualizations for topic models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be3d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# load the dictionary, corpus, and LDA model we created earlier:\n",
    "#dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\n",
    "#corpus = pickle.load(open('corpus.pkl', 'rb'))\n",
    "\n",
    "# If you generate a new model and change the number of topics, you may need to change the file name for the model (here, model5.gensim)\n",
    "#lda = ldamodel#gensim.models.ldamodel.LdaModel.load('model10.gensim')\n",
    "\n",
    "# import pyLDAvis and ready it for use in a notebook:\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# feed pyLDAvis the pieces generated from Gensim and create the visualization:\n",
    "lda_display = gensimvis.prepare(ldamodel, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ed055e",
   "metadata": {},
   "source": [
    "### Getting topic probabilities for each document\n",
    "\n",
    "You may want to know the probability estimates gensim assigns for each topic to a specific document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feabe3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.get_document_topics(corpus[120])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517053c7",
   "metadata": {},
   "source": [
    "let's take a look at all documents and add the probabilities to our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e35061",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topics = []\n",
    "for c in corpus:\n",
    "    document_topics.append(ldamodel.get_document_topics(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fbffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_df['topics'] = document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7211fb15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vol_df.sort_values(by='title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43232b29",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "* Try changing the number of topics.\n",
    "* Try building a topic model by document, rather than by page (this is probably way too involved for the workshop, but might be interesting to try later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6215aedc",
   "metadata": {},
   "source": [
    "### Analyzing a single document in the general topic model\n",
    "\n",
    "Take a look at the results for a single document (you'll need to look up the page number for a document)\n",
    "for example, you can look up the document for the first record: https://babel.hathitrust.org/cgi/pt?id=uc1.31378007786000&view=1up&seq=9                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4908c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ebf058",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_df.iloc[0]['page_tokens'][150:160]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc39328",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try finding a document with a more ambigous categorization. Does the more ambiguous categorization from Gensim match your general intuition about the document?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c0f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
