{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94be7c9f",
   "metadata": {},
   "source": [
    "## Multiple File Exploration and Analysis\n",
    "\n",
    "In the previous workbook, SingleFile, we used the FeatureReader to explore a single document. In the next two workbooks, \"Multifile-Prep\" and \"Multifile-Analysis\", we'll use the FeatureReader and Gensim to analyze a collection of documents and build a topic model.\n",
    "\n",
    "This workbook will prepare data for analysis, and Multifile-Analysis will load the data created in this worbook to build a topic model using Gensim. \n",
    "\n",
    "For this workshop, we'll continue to use a UCSF health sciences related dataset. However you should be able to swap in any of the sample datasets prepared by HathiTrust:\n",
    "\n",
    "https://analytics.hathitrust.org/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a2b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from htrc_features import FeatureReader, Volume\n",
    "import glob\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09128e09",
   "metadata": {},
   "source": [
    "### Read Data\n",
    "\n",
    "We'll use glob to recusively find all .bz2 files available in the directory structure, then append each file to a list of paths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1808a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "import glob\n",
    "for file in glob.glob('data/uc1/**/*.bz2', recursive=True):\n",
    "#for file in glob.glob('data/SOM-30Vol/uc1/**/*.bz2', recursive=True):\n",
    "    paths.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91040df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "705"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f788dcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/uc1/37087/uc1.31378007785978.json.bz2\n"
     ]
    }
   ],
   "source": [
    "print(paths[36])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c3fe53",
   "metadata": {},
   "source": [
    "### Prepare a dataset for a topic modeling exercise\n",
    "\n",
    "To illustrate topic modeling, we'll prepare a dataset consisting of records containing \"nursing\" or \"denistry\" in the title. Keep in mind, you don't need to do this to use topic modeling to analyze a dataset. For unsupervised machine learning, you don't need to pre-define your categories or topics - the algorithm will identify clusters of documents around potential topics of interest for you. However, for an exercise, it can help to have a sense of our topics as it will help us see how the algorithm is identifying clusters that emerge from the collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e478ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will take a few minutes to run.\n",
    "# to make it run faster, you may want to lower the sample size\n",
    "\n",
    "sample_size = 20\n",
    "i = 0\n",
    "fr = FeatureReader(paths)\n",
    "nursing_count = 0\n",
    "dentistry_count = 0\n",
    "vols = []\n",
    "vol_row_id = []\n",
    "for vol in fr.volumes():\n",
    "    title = vol.title.lower()\n",
    "    if 'nursing' in title and nursing_count < sample_size:\n",
    "        vols.append(vol)\n",
    "        nursing_count += 1\n",
    "    if 'dentistry' in title and dentistry_count < sample_size:\n",
    "        vols.append(vol)\n",
    "        dentistry_count += 1\n",
    "    if dentistry_count >= 20 and nursing_count >= sample_size:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60f3b9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b36df5",
   "metadata": {},
   "source": [
    "### Volumes\n",
    "\n",
    "We can print the title for each volume in our collection by iterating over each element in the vols collection we created in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c1a9d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Announcement of the College of Dentistry.\n",
      "Announcement of the College of Dentistry.\n",
      "School of Nursing.\n",
      "Announcement of the College of Dentistry.\n",
      "School of Nursing.\n",
      "School of Nursing.\n",
      "School of Nursing.\n",
      "School of Nursing.\n",
      "School of Nursing.\n",
      "School of Nursing.\n",
      "Announcement of the College of Dentistry.\n",
      "Announcement of the College of Dentistry.\n",
      "Announcement of the College of Dentistry.\n",
      "University of California, San Francisco. School of Dentistry yearbook.\n",
      "University of California, San Francisco. School of Dentistry yearbook.\n",
      "University of California, San Francisco. School of Dentistry yearbook.\n",
      "University of California, San Francisco. School of Dentistry yearbook.\n",
      "UCSF School of Dentistry bulletin.\n",
      "University of California, San Francisco. School of Dentistry yearbook.\n",
      "University of California, San Francisco. School of Dentistry yearbook.\n",
      "University of California, San Francisco. School of Dentistry yearbook.\n",
      "UCSF School of Dentistry bulletin.\n",
      "University of California, San Francisco. School of Dentistry yearbook.\n",
      "University of California, San Francisco. School of Dentistry yearbook.\n",
      "University of California, San Francisco. School of Dentistry yearbook.\n",
      "University of California, San Francisco. School of Dentistry yearbook.\n",
      "University of California, San Francisco. School of Dentistry yearbook.\n",
      "School of Nursing.\n",
      "School of Nursing.\n",
      "School of Nursing.\n",
      "School of Nursing.\n",
      "School of Nursing.\n",
      "School of Nursing.\n",
      "School of Nursing.\n",
      "School of Nursing.\n",
      "School of Nursing.\n",
      "School of Nursing.\n",
      "School of Nursing.\n"
     ]
    }
   ],
   "source": [
    "for v in vols:\n",
    "    print(v.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10839b07",
   "metadata": {},
   "source": [
    "### Individual record access\n",
    "\n",
    "We can access the metadata from the list for each record the same way we did with the single file case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a39d51a",
   "metadata": {},
   "source": [
    "vols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6189dfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Empty DataFrame\n",
      "Columns: [count]\n",
      "Index: []\n",
      "\n",
      "2                              count\n",
      "page section token      pos       \n",
      "2    body    CALIFORNIA UNK      1\n",
      "             CENTER     UNK      1\n",
      "             FRANCISCO  UNK      1\n",
      "             LIBRARY    UNK      1\n",
      "             MEDICAL    UNK      1\n",
      "             OF         UNK      1\n",
      "             SAN        UNK      1\n",
      "             UNIVERSITY UNK      1\n",
      "\n",
      "3 Empty DataFrame\n",
      "Columns: [count]\n",
      "Index: []\n",
      "\n",
      "4 Empty DataFrame\n",
      "Columns: [count]\n",
      "Index: []\n",
      "\n",
      "5 Empty DataFrame\n",
      "Columns: [count]\n",
      "Index: []\n",
      "\n",
      "6 Empty DataFrame\n",
      "Columns: [count]\n",
      "Index: []\n",
      "\n",
      "7                              count\n",
      "page section token      pos       \n",
      "7    body    $          $        1\n",
      "             &          CC       1\n",
      "             '          ''       3\n",
      "             *          SYM      1\n",
      "             -          :        1\n",
      "             .          .        5\n",
      "             /          :        1\n",
      "             1          CD       2\n",
      "             2          CD       1\n",
      "             3          CD       1\n",
      "             5J         NN       1\n",
      "             7          CD       1\n",
      "             ;          :        3\n",
      "             =          JJ       1\n",
      "             ?          .        1\n",
      "             @C         NNP      1\n",
      "             ALI        NNP      1\n",
      "             Bill       NNP      1\n",
      "             DEPARTMENT NNP      1\n",
      "             F0         NN       1\n",
      "             FQMA       NN       1\n",
      "             IVE        NN       1\n",
      "             IZ         NN       1\n",
      "             JF4        NN       1\n",
      "             M          NN       1\n",
      "             N          NN       1\n",
      "             OMSGL      NNP      1\n",
      "             QW         NN       1\n",
      "             RN         NN       1\n",
      "             RSITY      NN       1\n",
      "             SBENTAL    NNP      1\n",
      "             TF         NN       1\n",
      "             TWENTIETH  NNP      1\n",
      "             \\          SYM      1\n",
      "             `          ``       7\n",
      "             i          LS       1\n",
      "             j.         NN       1\n",
      "             m          NN       1\n",
      "             mi         NN       1\n",
      "             of         IN       1\n",
      "             qt         NN       1\n",
      "             the        DT       1\n",
      "             §          SYM      1\n",
      "             ﬁg-LEG     NN       1\n",
      "\n",
      "8 Empty DataFrame\n",
      "Columns: [count]\n",
      "Index: []\n",
      "\n",
      "9 Empty DataFrame\n",
      "Columns: [count]\n",
      "Index: []\n",
      "\n",
      "10                               count\n",
      "page section token       pos       \n",
      "10   body    ''          ''       1\n",
      "             ,           ,        1\n",
      "             .           .        1\n",
      "             California  NNP      1\n",
      "             Dentistry   NNP      1\n",
      "             Departments NNP      1\n",
      "             Medicine    NNP      1\n",
      "             Pharmacy    NNP      1\n",
      "             University  NNP      1\n",
      "             `           ``       1\n",
      "             and         CC       1\n",
      "             of          IN       3\n",
      "             the         DT       1\n",
      "\n",
      "11                          count\n",
      "page section token pos        \n",
      "11   body    #     #         1\n",
      "             %     NN        1\n",
      "             '     ''        1\n",
      "             ,     ,         8\n",
      "             --    :         1\n",
      "...                        ...\n",
      "             their PRP$      1\n",
      "             to    TO        3\n",
      "             who   WP        1\n",
      "             will  MD        1\n",
      "             wish  VBP       1\n",
      "\n",
      "[73 rows x 1 columns]\n",
      "\n",
      "12                         count\n",
      "page section token pos       \n",
      "12   body    '-    UNK      1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing only the first 10 token lists\n",
    "for i, p in enumerate(vols[0].pages()):\n",
    "    print(i+1, p.tokenlist())\n",
    "    print()\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb707d",
   "metadata": {},
   "source": [
    "### Exercise: Take a look at some other records and get a sense of how text is extracted\n",
    "\n",
    "* how complete is it?\n",
    "* what do you gain from relying exclusively on word count? what do you lose?\n",
    "* is there clutter? Are non-alphanumeric characters useful to you?\n",
    "* what do you lose if you don't know the position or part of speech of words? \n",
    "* how could varying transcription thoroughness and accuracy influence your research?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14137480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <th>section</th>\n",
       "      <th>lowercase</th>\n",
       "      <th>pos</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">body</th>\n",
       "      <th>california</th>\n",
       "      <th>UNK</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>center</th>\n",
       "      <th>UNK</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>francisco</th>\n",
       "      <th>UNK</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>library</th>\n",
       "      <th>UNK</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical</th>\n",
       "      <th>UNK</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">539</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">body</th>\n",
       "      <th>rmmmmmummmlmnn‘u‘mqggwllwl</th>\n",
       "      <th>UNK</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>~</th>\n",
       "      <th>UNK</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <th>UNK</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <th>UNK</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“!!!</th>\n",
       "      <th>UNK</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68030 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             count\n",
       "page section lowercase                  pos       \n",
       "2    body    california                 UNK      1\n",
       "             center                     UNK      1\n",
       "             francisco                  UNK      1\n",
       "             library                    UNK      1\n",
       "             medical                    UNK      1\n",
       "...                                            ...\n",
       "539  body    rmmmmmummmlmnn‘u‘mqggwllwl UNK      1\n",
       "             ~                          UNK      1\n",
       "             ‘                          UNK      1\n",
       "             ’                          UNK      1\n",
       "             “!!!                       UNK      1\n",
       "\n",
       "[68030 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "vols[0].tokenlist(case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5914ccac",
   "metadata": {},
   "source": [
    "### Cleaning Data\n",
    "\n",
    "In the previous workbook, we discussed the potential \"clutter\" in our text. We may not want punctuation, non-alphanumeric characters, or stop words, and we may want to lemmatize or stem some of our terms\n",
    "\n",
    "A full review of cleaning text data is beyond the scope of this workshop, though we will remove the stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c702c448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/boushey/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5623482f",
   "metadata": {},
   "source": [
    "### Create a bag of words\n",
    "\n",
    "This next bit of code is a little complicated. We're using some of the techniques discussed earlier for going line-by-line through the pages of each volume to create a bag of words model and term frequency vector for each page. \n",
    "\n",
    "For now, let's walk through this code, take a look at the output, and and discuss how it works. You may also want to refer back to the of bag-of-words visuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9243c47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845e7bb5061948f79e53b265f889d200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# note - tdqm is used to provide a progress bar, since this bit of code can take a while to run.\n",
    "# it's optional but can be useful to get a sense of how your code is progressing and how much longer it will\n",
    "# take to run\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "vol_df = pd.DataFrame(columns=['htid', 'page_number', 'page_tokens'])\n",
    "\n",
    "for vol in tqdm(vols, total=len(vols)):\n",
    "    title = vol.title\n",
    "    htid = vol.id\n",
    "    for page in vol.pages():\n",
    "        page_num = str(page).split(' ')[1]\n",
    "        page_df = page.tokenlist(section='body', case=False, pos=False)\n",
    "        \n",
    "        tkn_list = []\n",
    "        \n",
    "        for i, r in page_df.iterrows():\n",
    "            #print(i[0], i[1], i[2])\n",
    "            word = i[2]\n",
    "            count = r[0]\n",
    "            #print(word, count)\n",
    "            word = word.strip()\n",
    "            \n",
    "            if word not in en_stop and word.isalpha() and len(word) > 2:\n",
    "                for _ in range(count):\n",
    "                    tkn_list.append(word)\n",
    "        \n",
    "        # only include pages with at least 50 tokens. This helps avoid blank pages, etc.\n",
    "        if len(tkn_list) > 50 and 'nursing' in tkn_list and 'dentistry' in tkn_list:   \n",
    "        #if 'nursing' in tkn_list or 'dentistry' in tkn_list: \n",
    "            vol_df = vol_df.append({'title':title, 'htid': htid, 'page_number':  page_num, 'page_tokens': tkn_list}, ignore_index=True)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4dc75c",
   "metadata": {},
   "source": [
    "### Dataframe for Text Analysis\n",
    "\n",
    "The code above creates a dataframe with each document id, page number, the tokens (including duplicates) for each page, and the title for each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd086ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>htid</th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_tokens</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uc1.31378007786000</td>\n",
       "      <td>18</td>\n",
       "      <td>[albert, alfred, allen, alphabetically, anatom...</td>\n",
       "      <td>Announcement of the College of Dentistry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uc1.31378007786000</td>\n",
       "      <td>76</td>\n",
       "      <td>[absent, alfred, allen, alphabetically, anatom...</td>\n",
       "      <td>Announcement of the College of Dentistry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uc1.31378007786000</td>\n",
       "      <td>137</td>\n",
       "      <td>[absent, albert, albert, ardell, arthur, assis...</td>\n",
       "      <td>Announcement of the College of Dentistry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uc1.31378007786000</td>\n",
       "      <td>199</td>\n",
       "      <td>[academic, academic, academic, acceptable, adj...</td>\n",
       "      <td>Announcement of the College of Dentistry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uc1.31378007786000</td>\n",
       "      <td>239</td>\n",
       "      <td>[albert, ardell, arthur, assistant, assistant,...</td>\n",
       "      <td>Announcement of the College of Dentistry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>uc1.31378005266823</td>\n",
       "      <td>133</td>\n",
       "      <td>[acute, adjacent, ailable, allied, almost, alm...</td>\n",
       "      <td>School of Nursing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>uc1.31378005266823</td>\n",
       "      <td>195</td>\n",
       "      <td>[ambulatory, avenue, building, california, car...</td>\n",
       "      <td>School of Nursing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>uc1.31378005266823</td>\n",
       "      <td>198</td>\n",
       "      <td>[academic, account, addition, adjacent, admini...</td>\n",
       "      <td>School of Nursing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>uc1.31378005266823</td>\n",
       "      <td>199</td>\n",
       "      <td>[acute, adjacent, allied, almost, almost, anes...</td>\n",
       "      <td>School of Nursing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>uc1.31378005266823</td>\n",
       "      <td>204</td>\n",
       "      <td>[academic, academicians, actively, admission, ...</td>\n",
       "      <td>School of Nursing.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   htid page_number  \\\n",
       "0    uc1.31378007786000          18   \n",
       "1    uc1.31378007786000          76   \n",
       "2    uc1.31378007786000         137   \n",
       "3    uc1.31378007786000         199   \n",
       "4    uc1.31378007786000         239   \n",
       "..                  ...         ...   \n",
       "203  uc1.31378005266823         133   \n",
       "204  uc1.31378005266823         195   \n",
       "205  uc1.31378005266823         198   \n",
       "206  uc1.31378005266823         199   \n",
       "207  uc1.31378005266823         204   \n",
       "\n",
       "                                           page_tokens  \\\n",
       "0    [albert, alfred, allen, alphabetically, anatom...   \n",
       "1    [absent, alfred, allen, alphabetically, anatom...   \n",
       "2    [absent, albert, albert, ardell, arthur, assis...   \n",
       "3    [academic, academic, academic, acceptable, adj...   \n",
       "4    [albert, ardell, arthur, assistant, assistant,...   \n",
       "..                                                 ...   \n",
       "203  [acute, adjacent, ailable, allied, almost, alm...   \n",
       "204  [ambulatory, avenue, building, california, car...   \n",
       "205  [academic, account, addition, adjacent, admini...   \n",
       "206  [acute, adjacent, allied, almost, almost, anes...   \n",
       "207  [academic, academicians, actively, admission, ...   \n",
       "\n",
       "                                         title  \n",
       "0    Announcement of the College of Dentistry.  \n",
       "1    Announcement of the College of Dentistry.  \n",
       "2    Announcement of the College of Dentistry.  \n",
       "3    Announcement of the College of Dentistry.  \n",
       "4    Announcement of the College of Dentistry.  \n",
       "..                                         ...  \n",
       "203                         School of Nursing.  \n",
       "204                         School of Nursing.  \n",
       "205                         School of Nursing.  \n",
       "206                         School of Nursing.  \n",
       "207                         School of Nursing.  \n",
       "\n",
       "[208 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27959a",
   "metadata": {},
   "source": [
    "### Pickle\n",
    "\n",
    "We've created our dataframe. We'll save it to a directory in our workspace and load it for analysis in the next workbook.\n",
    "\n",
    "You may be wondering why we aren't using the to_csv method to export our data to a csv. The reason we're doing it with pickle (which writes the model to disk but can't be read like a csv) is that our page_tokens column contains lists, rather than single values. This can cause issues when writing to/reading from csv files. There are ways around this, but it may be easier to pickle the data if you don't need to read it outside a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0a04f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas to_csv will convert lists into strings, which will be a hassle.\n",
    "# better to pickle it. \n",
    "vol_df.to_pickle('processed_data/ucsf_medical.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e67c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca1d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "996f5775",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
